ğŸ§  AI Conversational Chatbot â€” n8n + Streamlit Integration
ğŸ“Œ Overview
This project is an AI-powered Conversational Chatbot that analyzes uploaded documents such as resumes and research papers.
It integrates Streamlit for the user interface and n8n for backend automation using Google Gemini (PaLM) to extract, process, and answer questions directly from the uploaded documents.

ğŸš€ Features

ğŸ§¾ Upload and analyze PDF, DOCX, or CSV files

ğŸ’¬ Ask natural language questions about the content

ğŸ¤– Uses n8n workflow with Google Gemini AI for intelligent responses

ğŸ’¡ Answers strictly from the uploaded document â€” no hallucinations

ğŸ§  Maintains short-term context using Memory Buffer in n8n

ğŸ§© Project Structure
project/
â”‚
â”œâ”€â”€ app.py                         # Main Streamlit app (home page)
â”‚
â”œâ”€â”€ requirements.txt                # Python dependencies
â”‚
â””â”€â”€ pages/
    â”œâ”€â”€ resume_chat.py             # Resume Q&A interface
    â””â”€â”€ research_chat.py           # Research/CSV Q&A interface

âš™ï¸ Setup Instructions
1ï¸âƒ£ Clone the Repository
git clone https://github.com/vijaymangore/AI-CONVERSATIONAL-CHATBOT.git
cd AI-CONVERSATIONAL-CHATBOT

2ï¸âƒ£ Create and Activate Virtual Environment
python -m venv venv
venv\Scripts\activate     # On Windows
# or
source venv/bin/activate  # On Mac/Linux

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt


requirements.txt

streamlit
requests

4ï¸âƒ£ Run the Streamlit App
streamlit run app.py


Now open the app in your browser at:
ğŸ‘‰ http://localhost:8501

ğŸ§  How It Works
Frontend (Streamlit)

Users upload a file (Resume or Research Paper).

They input a question via chat.

The app sends both file and question to a Webhook URL hosted on n8n.

Backend (n8n Workflow)

Workflow Summary:

Webhook Node: Receives uploaded file and question.

Extract from File: Extracts text from the uploaded file (PDF/DOC).

Google Gemini Chat Model: Uses Gemini to process language.

AI Agent: Answers question strictly from the document text.

Respond to Webhook: Sends the AI-generated answer back to Streamlit.

Workflow Webhooks:

Resume Chat Webhook â†’
https://sachintendulkar.app.n8n.cloud/webhook-test/298078b1-5ec3-4a35-811e-9e7063e5358e

Research Chat Webhook â†’
https://sachintendulkar.app.n8n.cloud/webhook-test/fd3ac7d5-612c-4bb8-86b6-dbbde3d0223c

ğŸ§© Files Description
app.py

Displays the project home page and navigation between pages.

pages/resume_chat.py

Handles document upload (resumes), connects to Resume n8n Webhook, and displays conversation.

pages/research_chat.py

Handles upload of research papers or datasets, connects to Research Webhook, and displays conversation.

ğŸ§ª Example Usage

Open the app.

Navigate to â€œResume Chat ğŸ’¼â€.

Upload a resume.pdf.

Ask: â€œWhat is the candidateâ€™s total experience?â€

Receive an AI-generated answer â€” extracted only from the uploaded file.

ğŸ› ï¸ Tech Stack
Layer	Technology
Frontend	Streamlit
Backend Automation	n8n
LLM	Google Gemini (PaLM)
Memory	LangChain Buffer Window
File Parsing	n8n Extract from File Node
Deployment	Streamlit Cloud + n8n Cloud
ğŸ“¤ Deployment
Streamlit Cloud

Push your project to GitHub.

Go to https://share.streamlit.io

Select your repo â†’ main branch â†’ app.py

Deploy ğŸš€

n8n Cloud

Your workflow (final project.json) can be imported directly to n8n:

Open your n8n workspace â†’ Import from file

Select final project.json

Activate the workflow.

ğŸ™ Credits

Developed by Vijaykumar Mangore

ğŸ“§ Email: vkmangore@gmail.com



